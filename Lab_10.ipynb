{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufqxI496yOqY",
        "colab_type": "text"
      },
      "source": [
        "**Problem statement 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUgrpNjiFQni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "#from sklearn import preprocessing, cross_validation\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_PmUj7oyRe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "allwalks = []\n",
        "\n",
        "for i in range(250):\n",
        "    randwalk = [0]\n",
        "    for x in range(100):\n",
        "        step = randwalk[-1]\n",
        "        dice = np.random.randint(1,7)\n",
        "        if dice <= 2 :\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice<=5:\n",
        "            step += 1\n",
        "\n",
        "        else:\n",
        "            step = step + np.random.randint(1,7)\n",
        "        \n",
        "    print(step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkK-hCK2AVL",
        "colab_type": "text"
      },
      "source": [
        "**Problem statement 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y73ff0x62MQD",
        "colab_type": "text"
      },
      "source": [
        "**Random data for multiple linear regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReY3UU3qzgyE",
        "colab_type": "code",
        "outputId": "c2385653-58f6-4c42-9fe5-799b276ee96c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(1)\n",
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "eps = scipy.stats.norm.rvs(0, 0.25,100)\n",
        "y = 1 + (0.4 * X[0]) + eps + (0.5 * X[1]) + (0.3 * X[2]) + (0.4 * X[3])\n",
        "data_mlr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y }\n",
        "df = pd.DataFrame(data_mlr)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "#df.to_csv('file1.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3         Y\n",
            "0  0.310326 -0.538983  0.522009 -0.630752  0.866218\n",
            "1  0.026933  1.005510 -1.519784  0.317596  1.772350\n",
            "2  1.454472 -1.948507  0.989502  1.673824  1.499090\n",
            "3  0.299680 -1.090324 -0.968199  0.285824  0.208772\n",
            "4  1.568637  0.042656 -0.204593  1.126121  2.364669\n",
            "          X0        X1        X2        X3         Y\n",
            "95 -0.408410  0.615359 -2.553963  1.017630  0.665650\n",
            "96  1.271942  0.739803  1.451475 -2.180999  1.384007\n",
            "97 -1.462029 -1.407781  0.657375  0.320367  0.282489\n",
            "98 -0.355275 -1.795455  0.762725 -0.701842 -0.191871\n",
            "99 -0.845194 -0.817530 -1.009229  0.328676 -0.035132\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.012668   -0.098384    0.002392    0.037210    0.993038\n",
            "std      0.984979    1.056384    0.890788    1.027167    0.826427\n",
            "min     -2.174584   -2.241255   -2.553963   -3.162631   -0.839570\n",
            "25%     -0.761235   -0.900435   -0.565406   -0.652427    0.476432\n",
            "50%     -0.013255   -0.008498   -0.023229    0.078830    1.022160\n",
            "75%      0.724811    0.740714    0.684799    0.733959    1.624228\n",
            "max      2.259437    2.192720    2.373255    2.320635    2.737757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8SJaKXqAdj6",
        "colab_type": "text"
      },
      "source": [
        "**Random data for logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhRfGyIbAjqB",
        "colab_type": "code",
        "outputId": "f8de5901-ab10-402d-ef37-6aaebeaef620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "a1 = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))/(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))))\n",
        "#print(a1)\n",
        "y1 = []\n",
        "for i in a1:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "#print(y1)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df1.head())\n",
        "print(df1.tail())\n",
        "print(df1.info())\n",
        "print(df1.describe())\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3  Y\n",
            "0  1.401957 -1.355933  1.594828 -0.749478  1\n",
            "1 -0.028443  0.594037 -0.282306  1.315282  1\n",
            "2 -0.262065 -0.633718 -0.054076 -0.785498  1\n",
            "3 -0.874858 -1.010066  0.765558 -0.558065  1\n",
            "4 -0.337952  1.498269  0.413932 -0.675617  1\n",
            "          X0        X1        X2        X3  Y\n",
            "95  1.488679 -0.205017 -0.989172  0.346556  1\n",
            "96  0.227252  0.510480  0.642715  1.009932  1\n",
            "97  0.222371 -0.404990 -0.309676 -1.455182  1\n",
            "98 -1.468875 -2.338533 -0.549930 -1.449617  0\n",
            "99  0.071898 -0.166012  0.201322  0.086252  1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.048892    0.031605    0.022196    0.021526    0.910000\n",
            "std      0.922258    1.095960    0.896893    0.908970    0.287623\n",
            "min     -2.538611   -2.338533   -2.145315   -2.376022    0.000000\n",
            "25%     -0.569378   -0.791644   -0.583555   -0.655579    1.000000\n",
            "50%     -0.025219   -0.113815    0.043722    0.086263    1.000000\n",
            "75%      0.715849    0.769525    0.695305    0.715316    1.000000\n",
            "max      1.871004    3.107332    2.707045    2.240492    1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBwMQqKdDetc",
        "colab_type": "text"
      },
      "source": [
        "**Random data for K means clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j_SGQjgfc5s",
        "colab_type": "code",
        "outputId": "aea4a974-4332-41e0-a3c8-5bb61add07b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        }
      },
      "source": [
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmeans)\n",
        "print(df3.head())\n",
        "print(df3.tail())\n",
        "print(df3.info())\n",
        "print(df3.describe())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1\n",
            "0 -0.080050 -1.173954\n",
            "1 -0.437135 -1.814662\n",
            "2 -1.536616 -1.373343\n",
            "3 -0.800002 -0.617649\n",
            "4 -0.983790 -0.900707\n",
            "          X0        X1\n",
            "95  2.560691  1.536328\n",
            "96  2.893297  1.566204\n",
            "97  1.902759  1.892117\n",
            "98  1.739779  2.184486\n",
            "99  1.379687  2.666957\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 1.7 KB\n",
            "None\n",
            "               X0          X1\n",
            "count  100.000000  100.000000\n",
            "mean     0.512684    0.399554\n",
            "std      1.537594    1.654819\n",
            "min     -1.949196   -1.982398\n",
            "25%     -0.852129   -1.174930\n",
            "50%      0.514673    0.427887\n",
            "75%      1.903072    2.055800\n",
            "max      2.994427    2.972533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1dxQMGDYIOq",
        "colab_type": "text"
      },
      "source": [
        "**Problem statement - 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wrb7gNZYaT1",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression using gradient descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa3knLkqGTZv",
        "colab_type": "code",
        "outputId": "20e1c23e-13f1-4d79-f39b-27cb6271d628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08297726333408594 0.18006939723867305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MRrum_2j6iC",
        "colab_type": "text"
      },
      "source": [
        "**Logistic regression using Gradient descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkzDhVrZZ6rq",
        "colab_type": "code",
        "outputId": "fee7db80-2cd4-4891-a54b-d6137d6b87f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.30250249211695207\n",
            "0.30246767315723116\n",
            "0.30243335732066357\n",
            "0.3023995359985447\n",
            "0.3023662007767267\n",
            "0.30233334342983526\n",
            "0.3023009559156906\n",
            "0.3022690303699237\n",
            "0.3022375591007821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AQXnM09oey8",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regreesion using L1 Regularization**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h29KsbGVpGYF",
        "colab_type": "code",
        "outputId": "41e6217c-1e0e-4d1a-b19a-054b3b1f22b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0738712823591653 0.18008044130900397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeqnzIJuqBrp",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regreesion using L2 Regularization**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQRD15PuqENj",
        "colab_type": "code",
        "outputId": "f14e67ca-fb40-4181-ed95-4e2cddf99e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08257998381739863 0.1800697210778034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WBibPW5rEi5",
        "colab_type": "text"
      },
      "source": [
        "**Logistic regression using L1 regualrization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqr8pUh8rJ0A",
        "colab_type": "code",
        "outputId": "eb717526-bf0e-46da-a5c4-fa7e2784f530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "-0.0957178147843501\n",
            "-0.49126928267553843\n",
            "-0.8838759664840703\n",
            "-1.2735829336825866\n",
            "-1.660434584454674\n",
            "-2.044474635211784\n",
            "-2.4257461061958714\n",
            "-2.804291312728332\n",
            "-3.1801518596965117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcrQi0KwrzX4",
        "colab_type": "text"
      },
      "source": [
        "**Logistic regression using L2 regualrization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYOUM896rrsz",
        "colab_type": "code",
        "outputId": "0727a761-73f0-4214-ea40-4487aad93c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.30253765266491595\n",
            "0.30260591111172064\n",
            "0.30273910226152506\n",
            "0.30293387149915413\n",
            "0.3031870022514592\n",
            "0.30349541047524015\n",
            "0.30385613937861167\n",
            "0.30426635436466415\n",
            "0.30472333818688496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsEFl-_mgS96",
        "colab_type": "text"
      },
      "source": [
        "**K Means Clustering Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdkxTDkgEMDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpLrjR_OiXo3",
        "colab_type": "code",
        "outputId": "71ef9137-7ed4-4b5b-b146-246ca6df623c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)\n",
        "        "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "155.2251271407831\n",
            "167.0476488109652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ArGImKtseys",
        "colab_type": "text"
      },
      "source": [
        "**Problem Statement - 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmUvIKGVtdO2",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression from scratch using OOPS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz42F7jnsjQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) # Type: Numpy float.\n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "\n",
        "if __name__ == \"__main__\": main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IX47f-btjwf",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression from scratch using OOPS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljHZlX41txID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV0M_cktt4kd",
        "colab_type": "text"
      },
      "source": [
        "**K Means from scratch using OOPS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuBU7YY_t90Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}